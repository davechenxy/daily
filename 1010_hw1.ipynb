{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import inv\n",
    "import random\n",
    "import math\n",
    "import sys\n",
    "\n",
    "\n",
    "def ada(X, Y, w, eta, iteration, lambdaL2):\n",
    "    s_grad = np.zeros(len(X[0]))\n",
    "    list_cost = []\n",
    "    for i in range(iteration):\n",
    "        hypo = np.dot(X,w)\n",
    "        loss = hypo - Y\n",
    "        cost = np.sum(loss**2)/len(X)\n",
    "        list_cost.append(cost)\n",
    "\n",
    "        grad = np.dot(X.T, loss)/len(X) + lambdaL2*w\n",
    "        s_grad += grad**2\n",
    "        ada = np.sqrt(s_grad)\n",
    "        w = w - eta*grad/ada\n",
    "    return w, list_cost\n",
    "\n",
    "\n",
    "def SGD(X, Y, w, eta, iteration, lambdaL2):\n",
    "    list_cost = []\n",
    "    for i in range(iteration):\n",
    "        hypo = np.dot(X,w)\n",
    "        loss = hypo - Y\n",
    "        cost = np.sum(loss**2)/len(X)\n",
    "        list_cost.append(cost)\n",
    "\n",
    "        rand = np.random.randint(0, len(X))\n",
    "        grad = X[rand]*loss[rand]/len(X) + lambdaL2*w\n",
    "        w = w - eta*grad\n",
    "    return w, list_cost\n",
    "\n",
    "def GD(X, Y, w, eta, iteration, lambdaL2):\n",
    "    list_cost = []\n",
    "    for i in range(iteration):\n",
    "        hypo = np.dot(X,w)\n",
    "        loss = hypo - Y\n",
    "        cost = np.sum(loss**2)/len(X)\n",
    "        list_cost.append(cost)\n",
    "\n",
    "        grad = np.dot(X.T, loss)/len(X) + lambdaL2 * w\n",
    "        w = w - eta*grad\n",
    "    return w, list_cost\n",
    "\n",
    "\n",
    "\n",
    "# 每一个维度储存一种污染物的咨询\n",
    "data = []\n",
    "for i in range(18):\n",
    "    data.append([])\n",
    "\n",
    "\n",
    "#read data\n",
    "n_row = 0\n",
    "text = open('data/train.csv', 'r', encoding='big5')\n",
    "row = csv.reader(text, delimiter=',')\n",
    "for r in row:\n",
    "    if n_row != 0:\n",
    "        for i in range(3,27):\n",
    "            if r[i] != \"NR\":\n",
    "                data[(n_row-1)%18].append(float(r[i]))\n",
    "            else:\n",
    "                data[(n_row-1)%18].append(float(0))\n",
    "    n_row = n_row + 1\n",
    "text.close\n",
    "\n",
    "\n",
    "#parse data to trainX and trainY\n",
    "x = []\n",
    "y = []\n",
    "for i in range(12):\n",
    "    for j in range(471):\n",
    "        x.append([])\n",
    "        for t in range(18):\n",
    "            for s in range(9):\n",
    "                x[471*i + j].append(data[t][480*i+j+s])\n",
    "        y.append(data[9][480*i+j+9])\n",
    "trainX = np.array(x) #每一行有9*18个数 每9个代表9天的某一种污染物\n",
    "trainY = np.array(y)\n",
    "\n",
    "#parse test data\n",
    "test_x = []\n",
    "n_row = 0\n",
    "text = open('data/test.csv' ,\"r\")\n",
    "row = csv.reader(text , delimiter= \",\")\n",
    "\n",
    "for r in row:\n",
    "    if n_row %18 == 0:\n",
    "        test_x.append([])\n",
    "        for i in range(2,11):\n",
    "            test_x[n_row//18].append(float(r[i]) )\n",
    "    else :\n",
    "        for i in range(2,11):\n",
    "            if r[i] !=\"NR\":\n",
    "                test_x[n_row//18].append(float(r[i]))\n",
    "            else:\n",
    "                test_x[n_row//18].append(0)\n",
    "    n_row = n_row+1\n",
    "text.close()\n",
    "test_x = np.array(test_x)\n",
    "\n",
    "#parse anser\n",
    "ans_y = []\n",
    "n_row = 0\n",
    "text = open('data/ans.csv', \"r\")\n",
    "row = csv.reader(text, delimiter=\",\")\n",
    "\n",
    "for r in row:\n",
    "    ans_y.append(r[1])\n",
    "\n",
    "ans_y = ans_y[1:]\n",
    "ans_y = np.array(list(map(int, ans_y)))\n",
    "\n",
    "\n",
    "# add bias\n",
    "test_x = np.concatenate((np.ones((test_x.shape[0],1)),test_x), axis=1)\n",
    "trainX = np.concatenate((np.ones((trainX.shape[0],1)), trainX), axis=1)\n",
    "\n",
    "\n",
    "#train data\n",
    "w = np.zeros(len(trainX[0]))\n",
    "w_sgd, cost_list_sgd = SGD(trainX, trainY, w, eta=0.0001, iteration=20000, lambdaL2=0)\n",
    "# w_sgd50, cost_list_sgd50 = SGD(trainX, trainY, w, eta=0.0001, iteration=20000, lambdaL2=50)\n",
    "w_ada, cost_list_ada = ada(trainX, trainY, w, eta=1, iteration=20000, lambdaL2=0)\n",
    "# w_gd, cost_list_gd = SGD(trainX, trainY, w, eta=0.0001, iteration=20000, lambdaL2=0)\n",
    "\n",
    "#close form\n",
    "w_cf = inv(trainX.T.dot(trainX)).dot(trainX.T).dot(trainY)\n",
    "cost_wcf = np.sum((trainX.dot(w_cf)-trainY)**2) / len(trainX)\n",
    "hori = [cost_wcf for i in range(20000-3)]\n",
    "\n",
    "\n",
    "\n",
    "#output testdata\n",
    "y_ada = np.dot(test_x, w_ada)\n",
    "y_sgd = np.dot(test_x, w_sgd)\n",
    "y_cf = np.dot(test_x, w_cf)\n",
    "\n",
    "#csv format\n",
    "ans = []\n",
    "for i in range(len(test_x)):\n",
    "    ans.append([\"id_\"+str(i)])\n",
    "    a = np.dot(w_ada,test_x[i])\n",
    "    ans[i].append(a)\n",
    "\n",
    "filename = \"result/predict.csv\"\n",
    "text = open(filename, \"w+\")\n",
    "s = csv.writer(text,delimiter=',',lineterminator='\\n')\n",
    "s.writerow([\"id\",\"value\"])\n",
    "for i in range(len(ans)):\n",
    "    s.writerow(ans[i])\n",
    "text.close()\n",
    "\n",
    "\n",
    "#plot training data with different gradiant method\n",
    "plt.plot(np.arange(len(cost_list_ada[3:])), cost_list_ada[3:], 'b', label=\"ada\")\n",
    "plt.plot(np.arange(len(cost_list_sgd[3:])), cost_list_sgd[3:], 'g', label='sgd')\n",
    "# plt.plot(np.arange(len(cost_list_sgd50[3:])), cost_list_sgd50[3:], 'c', label='sgd50')\n",
    "# plt.plot(np.arange(len(cost_list_gd[3:])), cost_list_gd[3:], 'r', label='gd')\n",
    "plt.plot(np.arange(len(cost_list_ada[3:])), hori, 'y--', label='close-form')\n",
    "plt.title('Train Process')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss Function(Quadratic)')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(os.path.dirname(__file__), \"figures/TrainProcess\"))\n",
    "plt.show()\n",
    "\n",
    "#plot fianl answer\n",
    "plt.figure()\n",
    "plt.subplot(131)\n",
    "plt.title('CloseForm')\n",
    "plt.xlabel('dataset')\n",
    "plt.ylabel('pm2.5')\n",
    "plt.plot(np.arange((len(ans_y))), ans_y, 'r,')\n",
    "plt.plot(np.arange(240), y_cf, 'b')\n",
    "plt.subplot(132)\n",
    "plt.title('ada')\n",
    "plt.xlabel('dataset')\n",
    "plt.ylabel('pm2.5')\n",
    "plt.plot(np.arange((len(ans_y))), ans_y, 'r,')\n",
    "plt.plot(np.arange(240), y_ada, 'g')\n",
    "plt.subplot(133)\n",
    "plt.title('sgd')\n",
    "plt.xlabel('dataset')\n",
    "plt.ylabel('pm2.5')\n",
    "plt.plot(np.arange((len(ans_y))), ans_y, 'r,')\n",
    "plt.plot(np.arange(240), y_sgd, 'b')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(os.path.dirname(__file__), \"figures/Compare\"))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gluon] *",
   "language": "python",
   "name": "conda-env-gluon-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
